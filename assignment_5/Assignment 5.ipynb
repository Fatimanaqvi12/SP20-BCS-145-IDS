{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0953d331",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de48486e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn import metrics, model_selection\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('gender-prediction.csv')\n",
    "data.head()\n",
    "\n",
    "labels = preprocessing.LabelEncoder()\n",
    "\n",
    "beard_new = labels.fit_transform(data.beard)\n",
    "hair_length_new = labels.fit_transform(data.hair_length)\n",
    "scarf_new= labels.fit_transform(data.scarf)\n",
    "eye_color_new = labels.fit_transform(data.eye_color)\n",
    "gender_new = labels.fit_transform(data.gender)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4de67c76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>shoe_size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>176</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>165</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>132</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>138</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>197</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>65</td>\n",
       "      <td>99</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>61</td>\n",
       "      <td>98</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>67</td>\n",
       "      <td>119</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>70</td>\n",
       "      <td>190</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>62</td>\n",
       "      <td>142</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    height  weight  shoe_size\n",
       "0       71     176         44\n",
       "1       68     165         41\n",
       "2       62     132         37\n",
       "3       65     138         38\n",
       "4       70     197         43\n",
       "..     ...     ...        ...\n",
       "75      65      99         39\n",
       "76      61      98         37\n",
       "77      67     119         40\n",
       "78      70     190         43\n",
       "79      62     142         37\n",
       "\n",
       "[80 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.drop(['beard','hair_length','scarf','eye_color','gender'],axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8393b190",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = list(zip(df.height, df.weight, beard_new, hair_length_new, df.shoe_size, scarf_new, eye_color_new))\n",
    "y = gender_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abd1d45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d12ee7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25a1c90c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  1]\n",
      " [ 0 15]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.92      0.96        12\n",
      "           1       0.94      1.00      0.97        15\n",
      "\n",
      "    accuracy                           0.96        27\n",
      "   macro avg       0.97      0.96      0.96        27\n",
      "weighted avg       0.97      0.96      0.96        27\n",
      "\n",
      "Accuracy:  0.9629629629629629\n"
     ]
    }
   ],
   "source": [
    "#67%-33% split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,random_state=42)\n",
    "rfc = RandomForestClassifier(n_estimators= 50)\n",
    "rfc.fit(X_train, y_train)\n",
    "pred = rfc.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"Accuracy: \", accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c77e4c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 0]\n",
      " [0 9]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n",
      "Accuracy:  1.0\n"
     ]
    }
   ],
   "source": [
    "#80%-20% split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=42)\n",
    "rfc = RandomForestClassifier(n_estimators= 50)\n",
    "rfc.fit(X_train, y_train)\n",
    "pred = rfc.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,pred))\n",
    "print(\"Accuracy: \", accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cad84d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af1eeaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48a45738",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "249a832a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9  3]\n",
      " [ 4 11]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.75      0.72        12\n",
      "           1       0.79      0.73      0.76        15\n",
      "\n",
      "    accuracy                           0.74        27\n",
      "   macro avg       0.74      0.74      0.74        27\n",
      "weighted avg       0.74      0.74      0.74        27\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#67%-33% split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,random_state=42)\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e0f1223e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 2]\n",
      " [4 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.71      0.63         7\n",
      "           1       0.71      0.56      0.63         9\n",
      "\n",
      "    accuracy                           0.62        16\n",
      "   macro avg       0.63      0.63      0.63        16\n",
      "weighted avg       0.64      0.62      0.63        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#80%-20% split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=42)\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea93ba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Multilayer Perceptron "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bc27c63a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e346ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c9084e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  2]\n",
      " [ 1 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.83      0.87        12\n",
      "           1       0.88      0.93      0.90        15\n",
      "\n",
      "    accuracy                           0.89        27\n",
      "   macro avg       0.89      0.88      0.89        27\n",
      "weighted avg       0.89      0.89      0.89        27\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#67%-33% split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33,random_state=42)\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0fcafaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:692: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (200) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 2]\n",
      " [1 8]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.71      0.77         7\n",
      "           1       0.80      0.89      0.84         9\n",
      "\n",
      "    accuracy                           0.81        16\n",
      "   macro avg       0.82      0.80      0.81        16\n",
      "weighted avg       0.81      0.81      0.81        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#80%-20% split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=42)\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "100beb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping beard and scraf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7a591364",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_new = list(zip(df.height, df.weight, hair_length_new, df.shoe_size, eye_color_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "858358de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f698515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 0]\n",
      " [0 9]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         7\n",
      "           1       1.00      1.00      1.00         9\n",
      "\n",
      "    accuracy                           1.00        16\n",
      "   macro avg       1.00      1.00      1.00        16\n",
      "weighted avg       1.00      1.00      1.00        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#80%-20% split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=42)\n",
    "rfc = RandomForestClassifier(n_estimators= 50)\n",
    "rfc.fit(X_train, y_train)\n",
    "pred = rfc.predict(X_test)\n",
    "\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "de2e3c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#multilayer Perceptron\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1c02c01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3 4]\n",
      " [2 7]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.43      0.50         7\n",
      "           1       0.64      0.78      0.70         9\n",
      "\n",
      "    accuracy                           0.62        16\n",
      "   macro avg       0.62      0.60      0.60        16\n",
      "weighted avg       0.62      0.62      0.61        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#80%-20% split\n",
    "model = MLPClassifier()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=42)\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "20b75e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5 2]\n",
      " [4 5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.71      0.63         7\n",
      "           1       0.71      0.56      0.63         9\n",
      "\n",
      "    accuracy                           0.62        16\n",
      "   macro avg       0.63      0.63      0.63        16\n",
      "weighted avg       0.64      0.62      0.63        16\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#80%-20% split\n",
    "model = SVC()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=42)\n",
    "model.fit(X_train,y_train)\n",
    "predictions = model.predict(X_test)\n",
    "print(confusion_matrix(y_test,predictions))\n",
    "print(classification_report(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b3e2049",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "496a6be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import LeavePOut\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "918e89b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Score: 0.9569051204144372\n"
     ]
    }
   ],
   "source": [
    "model= DecisionTreeClassifier()\n",
    "X_pp = preprocessing.StandardScaler().fit(X).transform(X)\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits = 4, test_size = 0.5, random_state=1)\n",
    "sss.get_n_splits(X_pp, y)\n",
    "\n",
    "f1_scores = []\n",
    "\n",
    "for train_index, test_index in sss.split(X_pp, y):\n",
    "    X_train, X_test = X_pp[train_index], X_pp[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    prediction = model.predict(X_test)\n",
    "\n",
    "    f1_scores.append(f1_score(y_test, prediction))    \n",
    "\n",
    "print(\"Average F1 Score:\", (sum(f1_scores) / len(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "869fa560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average F1 Score: 0.9569051204144372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n",
      "F:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1580: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    }
   ],
   "source": [
    "lpo = LeavePOut(1)\n",
    "lpo.get_n_splits(X, y)\n",
    "f1_score = cross_val_score(model, X, y, scoring = \"f1\", cv = lpo)\n",
    "\n",
    "print(\"Average F1 Score:\", (sum(f1_scores) / len(f1_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f9a20075",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72d4a08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48a15a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>beard</th>\n",
       "      <th>hair_length</th>\n",
       "      <th>shoe_size</th>\n",
       "      <th>scarf</th>\n",
       "      <th>eye_color</th>\n",
       "      <th>gender</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>71</td>\n",
       "      <td>176</td>\n",
       "      <td>yes</td>\n",
       "      <td>short</td>\n",
       "      <td>44</td>\n",
       "      <td>no</td>\n",
       "      <td>black</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>68</td>\n",
       "      <td>165</td>\n",
       "      <td>no</td>\n",
       "      <td>bald</td>\n",
       "      <td>41</td>\n",
       "      <td>no</td>\n",
       "      <td>black</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>132</td>\n",
       "      <td>no</td>\n",
       "      <td>medium</td>\n",
       "      <td>37</td>\n",
       "      <td>yes</td>\n",
       "      <td>blue</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>65</td>\n",
       "      <td>138</td>\n",
       "      <td>no</td>\n",
       "      <td>long</td>\n",
       "      <td>38</td>\n",
       "      <td>no</td>\n",
       "      <td>gray</td>\n",
       "      <td>female</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70</td>\n",
       "      <td>197</td>\n",
       "      <td>yes</td>\n",
       "      <td>medium</td>\n",
       "      <td>43</td>\n",
       "      <td>no</td>\n",
       "      <td>gray</td>\n",
       "      <td>male</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   height  weight beard hair_length  shoe_size scarf eye_color  gender\n",
       "0      71     176   yes       short         44    no     black    male\n",
       "1      68     165    no        bald         41    no     black    male\n",
       "2      62     132    no      medium         37   yes      blue  female\n",
       "3      65     138    no        long         38    no      gray  female\n",
       "4      70     197   yes      medium         43    no      gray    male"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('question4.csv')\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a43b2e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = data.drop(['beard','hair_length','scarf','eye_color','gender'],axis=1)\n",
    "x = list(zip(gb.height, gb.weight, beard_new, hair_length_new, gb.shoe_size, scarf_new, eye_color_new))\n",
    "Y = gender_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5a194d9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[10  2]\n",
      " [ 0 15]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91        12\n",
      "           1       0.88      1.00      0.94        15\n",
      "\n",
      "    accuracy                           0.93        27\n",
      "   macro avg       0.94      0.92      0.92        27\n",
      "weighted avg       0.93      0.93      0.92        27\n",
      "\n",
      "Accuracy = 0.9259259259259259\n"
     ]
    }
   ],
   "source": [
    "model = GaussianNB() \n",
    "x_train, x_test, Y_train, Y_test = train_test_split(x, Y, test_size=0.33,random_state=42)\n",
    "model.fit(x_train,Y_train)\n",
    "model.fit(x_train, Y_train)  \n",
    "predictions = model.predict(x_test)\n",
    "print(confusion_matrix(Y_test,predictions))\n",
    "print(classification_report(Y_test,predictions))\n",
    "print(\"Accuracy =\", accuracy_score(Y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
